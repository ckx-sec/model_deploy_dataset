# Multi-Engine Inference

A project to build and run AI models using multiple inference engines on ARM Linux.
This project is inspired by [lite.ai.toolkit](https://github.com/xlite-dev/lite.ai.toolkit).

## Goal

The main goal is to provide a unified C++ API for different inference engines and provide a simple way to build them for ARM Linux.

## Supported Engines

- [ ] ONNXRuntime
- [ ] MNN
- [ ] NCNN
- [ ] TNN 